import os
import torch
from transformers import T5Tokenizer, T5ForConditionalGeneration
import subprocess

from ai.dataset import CodeDataset


def test_model(dataset_dir, model_dir):
    # Load the saved model and tokenizer
    print(f"Loading model and tokenizer from {model_dir}")
    tokeniser = T5Tokenizer.from_pretrained(model_dir)
    model = T5ForConditionalGeneration.from_pretrained(model_dir)
    model.eval()

    # load dataset
    print(f"Loading dataset from {dataset_dir}")
    dataset = CodeDataset(dataset_dir=dataset_dir,
                          tokeniser=tokeniser, max_length=512)

    # iterate through dataset and validate
    for i, data in enumerate(dataset):
        inefficient_code = data["input_ids"]
        expected_code = data["labels"]
        input_data = data["input_data"]
        expected_output = data["expected_output"]

        print("Tokenized input:", inefficient_code)
        print("Decoded input:", tokeniser.decode(
            inefficient_code, skip_special_tokens=True))

        # Generate output
        with torch.no_grad():
            output_ids = model.generate(inefficient_code.unsqueeze(0))

        # Check if there's an output
        if output_ids is None or torch.all(output_ids == 0):
            print("No output generated by the model.")
            continue

        print(f"Generated Output IDs: {output_ids}")

        # Decode the output
        generated_code = tokeniser.decode(
            output_ids[0], skip_special_tokens=True)
        print("\nGenerated Code:")
        print(generated_code)

        # Validate the generated code by running it and comparing the output
        try:
            for j, input_str in enumerate(input_data):
                result = subprocess.run(
                    ["python", "-c", generated_code],
                    input=input_str,
                    capture_output=True,
                    text=True,
                    timeout=10
                )
                actual_output = result.stdout
                error_output = result.stderr
                print("\nActual Output:")
                print(actual_output)
                if error_output:
                    print("\nError Output:")
                    print(error_output)

                if actual_output.strip() == expected_output[j].strip():
                    print("The generated code produces the expected output.")
                else:
                    print("The generated code does not produce the expected output.")
                    print(f"Expected Output: {expected_output[j]}")
                    print(f"Actual Output: {actual_output}")

        except subprocess.TimeoutExpired:
            print("The generated code took too long to execute.")
        except Exception as e:
            print(f"An error occurred while executing the generated code: {e}")


if __name__ == "__main__":
    dataset_dir = os.path.join(os.path.dirname(
        __file__), "ai/datasets/GEC/TEST_DEV")
    model_dir = os.path.join(os.path.dirname(
        __file__), "ai/models/final_model")
    test_model(dataset_dir, model_dir)
